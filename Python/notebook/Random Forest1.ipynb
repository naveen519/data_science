{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proj_id</th>\n",
       "      <th>project_nm</th>\n",
       "      <th>date</th>\n",
       "      <th>Order_1</th>\n",
       "      <th>Order_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>order_0222</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>322110</td>\n",
       "      <td>322073</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>order_0222</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>321741</td>\n",
       "      <td>322110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>order_0222</td>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>321578</td>\n",
       "      <td>321741</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>order_0222</td>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>322420</td>\n",
       "      <td>321578</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>order_0222</td>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>321914</td>\n",
       "      <td>322420</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proj_id  project_nm      date  Order_1  Order_2  count\n",
       "0        1  order_0222  1/1/2017   322110   322073      3\n",
       "1        1  order_0222  1/2/2017   321741   322110      4\n",
       "2        1  order_0222  1/3/2017   321578   321741      5\n",
       "3        1  order_0222  1/4/2017   322420   321578      6\n",
       "4        1  order_0222  1/5/2017   321914   322420      7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "\n",
    "import datetime\n",
    "\n",
    "os.chdir('C:\\\\Analytics\\\\Projects\\\\Forecasting')\n",
    "# Read in data and display first 5 rows\n",
    "features = pd.read_csv('hourly.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.dropna(axis= 0,how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (365, 6)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of our features is:', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proj_id        int64\n",
       "project_nm    object\n",
       "date          object\n",
       "Order_1        int64\n",
       "Order_2        int64\n",
       "count          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['date'] =  pd.to_datetime(features['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['day_of_week'] = features['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[[\"Order_1\",\"Order_2\",\"day_of_week\",\"count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order_1         int64\n",
       "Order_2         int64\n",
       "day_of_week    object\n",
       "count           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for each column\n",
    "#features.describe()\n",
    "\n",
    "#features[\"month\"] = features.month.astype(object)\n",
    "#features[\"qtr\"] = features.qtr.astype(object)\n",
    "#features[\"weeks\"] = features.weeks.astype(object)\n",
    "#features[\"day\"] = features.day.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "#features = pd.get_dummies(features)\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "#features.iloc[:,:].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['count'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('count', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (273, 3)\n",
      "Training Labels Shape: (273,)\n",
      "Testing Features Shape: (92, 3)\n",
      "Testing Labels Shape: (92,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "\n",
    "with open('C:\\\\Analytics\\\\Projects\\\\Forecasting\\\\model', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 261643.84 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "#predictions = rf.predict(test_features)\n",
    "\n",
    "# in your prediction file                                                                                                                                                                                                           \n",
    "\n",
    "with open('C:\\\\Analytics\\\\Projects\\\\Forecasting\\\\model', 'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "\n",
    "#18th (17th and 16th) #32111\n",
    "#19th (18th and 17th)\n",
    "#20th (19th and 18th )\n",
    "\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 323819.861, 1214248.323,  626032.014,  796168.363, 1276542.436,\n",
       "        379066.968,  419698.532,  650958.527, 1121403.547,  665472.745,\n",
       "        508675.56 , 3210686.269, 1914362.91 ,  762420.299, 1971544.867,\n",
       "       1920648.753,  411894.081, 1872712.294, 2105901.996,  370236.089,\n",
       "        925315.301,  836795.488,  406480.887, 1647233.519, 1089134.581,\n",
       "        334961.284,  326570.217,  323558.101,  629141.574,  325449.681,\n",
       "        424645.927, 2009984.225, 3122470.35 ,  392656.948,  583262.069,\n",
       "       2027826.88 , 3147654.205,  984365.441,  327263.616, 2432030.371,\n",
       "        375138.179, 1265073.953, 1172630.854,  510541.703, 1955791.616,\n",
       "       3218141.378, 1650413.545, 2423679.099,  323995.561, 1818135.835,\n",
       "       3221959.423,  491922.23 , 2380785.365,  777675.98 ,  692222.73 ,\n",
       "        326271.008,  817120.362,  378471.299,  323346.752,  628569.802,\n",
       "       2123879.947,  480755.184,  626352.835, 1318478.858,  454670.622,\n",
       "        347801.7  , 2403219.196,  446218.541, 3208183.263, 1652931.189,\n",
       "        630242.068,  328893.922, 1625072.555, 3107077.544,  335554.372,\n",
       "       3154254.913,  344584.819, 1812600.703,  330017.479,  532055.203,\n",
       "       3187778.057,  383652.565,  335897.343, 2119354.189, 1006282.273,\n",
       "       1652678.662,  353749.788, 1632670.732, 2096010.745, 1995596.842,\n",
       "        922081.177, 3233671.68 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.51 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Model and Report Results\n",
    "\n",
    "#There are two approaches to get under the hood of the random forest: \n",
    "    #First, we can look at a single tree in the forest, and \n",
    "    #Second, we can look at the feature importances of our explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Order_1              Importance: 0.86\n",
      "Variable: Order_2              Importance: 0.05\n",
      "Variable: weeks_29.0           Importance: 0.01\n",
      "Variable: weeks_33.0           Importance: 0.01\n",
      "Variable: day_12.0             Importance: 0.01\n",
      "Variable: yr                   Importance: 0.0\n",
      "Variable: National_holiday     Importance: 0.0\n",
      "Variable: natural_disturbances Importance: 0.0\n",
      "Variable: Fulfillment_backlogs Importance: 0.0\n",
      "Variable: shipment_backlog     Importance: 0.0\n",
      "Variable: month_1.0            Importance: 0.0\n",
      "Variable: month_2.0            Importance: 0.0\n",
      "Variable: month_3.0            Importance: 0.0\n",
      "Variable: month_4.0            Importance: 0.0\n",
      "Variable: month_5.0            Importance: 0.0\n",
      "Variable: month_6.0            Importance: 0.0\n",
      "Variable: month_7.0            Importance: 0.0\n",
      "Variable: month_8.0            Importance: 0.0\n",
      "Variable: month_9.0            Importance: 0.0\n",
      "Variable: month_10.0           Importance: 0.0\n",
      "Variable: month_11.0           Importance: 0.0\n",
      "Variable: month_12.0           Importance: 0.0\n",
      "Variable: qtr_1.0              Importance: 0.0\n",
      "Variable: qtr_2.0              Importance: 0.0\n",
      "Variable: qtr_3.0              Importance: 0.0\n",
      "Variable: qtr_4.0              Importance: 0.0\n",
      "Variable: weeks_1.0            Importance: 0.0\n",
      "Variable: weeks_2.0            Importance: 0.0\n",
      "Variable: weeks_3.0            Importance: 0.0\n",
      "Variable: weeks_4.0            Importance: 0.0\n",
      "Variable: weeks_5.0            Importance: 0.0\n",
      "Variable: weeks_6.0            Importance: 0.0\n",
      "Variable: weeks_7.0            Importance: 0.0\n",
      "Variable: weeks_8.0            Importance: 0.0\n",
      "Variable: weeks_9.0            Importance: 0.0\n",
      "Variable: weeks_10.0           Importance: 0.0\n",
      "Variable: weeks_11.0           Importance: 0.0\n",
      "Variable: weeks_12.0           Importance: 0.0\n",
      "Variable: weeks_13.0           Importance: 0.0\n",
      "Variable: weeks_14.0           Importance: 0.0\n",
      "Variable: weeks_15.0           Importance: 0.0\n",
      "Variable: weeks_16.0           Importance: 0.0\n",
      "Variable: weeks_17.0           Importance: 0.0\n",
      "Variable: weeks_18.0           Importance: 0.0\n",
      "Variable: weeks_19.0           Importance: 0.0\n",
      "Variable: weeks_20.0           Importance: 0.0\n",
      "Variable: weeks_21.0           Importance: 0.0\n",
      "Variable: weeks_22.0           Importance: 0.0\n",
      "Variable: weeks_23.0           Importance: 0.0\n",
      "Variable: weeks_24.0           Importance: 0.0\n",
      "Variable: weeks_25.0           Importance: 0.0\n",
      "Variable: weeks_26.0           Importance: 0.0\n",
      "Variable: weeks_27.0           Importance: 0.0\n",
      "Variable: weeks_28.0           Importance: 0.0\n",
      "Variable: weeks_30.0           Importance: 0.0\n",
      "Variable: weeks_31.0           Importance: 0.0\n",
      "Variable: weeks_32.0           Importance: 0.0\n",
      "Variable: weeks_34.0           Importance: 0.0\n",
      "Variable: weeks_35.0           Importance: 0.0\n",
      "Variable: weeks_36.0           Importance: 0.0\n",
      "Variable: weeks_37.0           Importance: 0.0\n",
      "Variable: weeks_38.0           Importance: 0.0\n",
      "Variable: weeks_39.0           Importance: 0.0\n",
      "Variable: weeks_40.0           Importance: 0.0\n",
      "Variable: weeks_41.0           Importance: 0.0\n",
      "Variable: weeks_42.0           Importance: 0.0\n",
      "Variable: weeks_43.0           Importance: 0.0\n",
      "Variable: weeks_44.0           Importance: 0.0\n",
      "Variable: weeks_45.0           Importance: 0.0\n",
      "Variable: weeks_46.0           Importance: 0.0\n",
      "Variable: weeks_47.0           Importance: 0.0\n",
      "Variable: weeks_48.0           Importance: 0.0\n",
      "Variable: weeks_49.0           Importance: 0.0\n",
      "Variable: weeks_50.0           Importance: 0.0\n",
      "Variable: weeks_51.0           Importance: 0.0\n",
      "Variable: weeks_52.0           Importance: 0.0\n",
      "Variable: weeks_53.0           Importance: 0.0\n",
      "Variable: day_1.0              Importance: 0.0\n",
      "Variable: day_2.0              Importance: 0.0\n",
      "Variable: day_3.0              Importance: 0.0\n",
      "Variable: day_4.0              Importance: 0.0\n",
      "Variable: day_5.0              Importance: 0.0\n",
      "Variable: day_6.0              Importance: 0.0\n",
      "Variable: day_7.0              Importance: 0.0\n",
      "Variable: day_8.0              Importance: 0.0\n",
      "Variable: day_9.0              Importance: 0.0\n",
      "Variable: day_10.0             Importance: 0.0\n",
      "Variable: day_11.0             Importance: 0.0\n",
      "Variable: day_13.0             Importance: 0.0\n",
      "Variable: day_14.0             Importance: 0.0\n",
      "Variable: day_15.0             Importance: 0.0\n",
      "Variable: day_16.0             Importance: 0.0\n",
      "Variable: day_17.0             Importance: 0.0\n",
      "Variable: day_18.0             Importance: 0.0\n",
      "Variable: day_19.0             Importance: 0.0\n",
      "Variable: day_20.0             Importance: 0.0\n",
      "Variable: day_21.0             Importance: 0.0\n",
      "Variable: day_22.0             Importance: 0.0\n",
      "Variable: day_23.0             Importance: 0.0\n",
      "Variable: day_24.0             Importance: 0.0\n",
      "Variable: day_25.0             Importance: 0.0\n",
      "Variable: day_26.0             Importance: 0.0\n",
      "Variable: day_27.0             Importance: 0.0\n",
      "Variable: day_28.0             Importance: 0.0\n",
      "Variable: day_29.0             Importance: 0.0\n",
      "Variable: day_30.0             Importance: 0.0\n",
      "Variable: day_31.0             Importance: 0.0\n",
      "Variable: status_Validation    Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Variable Importances\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import MySQLdb\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "conn = MySQLdb.connect (host = \"10.100.112.85\",user = \"root\",\n",
    "                        passwd = \"passw0rd\",\n",
    "                        db = \"connect_test\")\n",
    "cursor = conn.cursor ()\n",
    "with open('/home/ACPO/nikhil.suryavanshi/docker-setup/data/PYTHON/output', 'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "\n",
    "query=(\"select sum(IF(rank = 1, count, NULL)) AS Count1,sum(IF(rank = 2,count, NULL)) AS Count2 from (select A.count, @curRank := @curRank + 1 AS rank,Datename from (SELECT  SUM(FLD11)AS count,date  as Datename from connect_test.hourly where fld10 = 'Validation'  AND date BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 2 DAY) AND CURRENT_DATE() group by date )A, (SELECT @curRank := 0) r)M\")\t\n",
    "\n",
    "cursor.execute(query)\t\n",
    "for row in cursor:\n",
    "\ttest_features=np.array([[row[0],row[1],datetime.datetime.now().strftime(\"%A\")]])\n",
    "\n",
    "print(test_features)\n",
    "dateData=[]\n",
    "predictedData=[]\n",
    "df=pd.DataFrame()\n",
    "\n",
    "df=pd.DataFrame(columns=[\"proj_id\",\"project_nm\",\"date\", \"yr\", \"qtr\", \"mth\", \"wk\", \"day\", \"hr\", \"fld1\", \"fld2\", \"fld3\", \"fld4\", \"fld5\", \"fld6\", \"fld7\", \"fld8\", \"fld9\", \"fld10\", \"fld11\", \"fld12\", \"fld13\", \"fld14\", \"fld15\", \"fld16\", \"fld17\", \"fld18\", \"fld19\", \"fld20\", \"fld21\", \"fld22\", \"fld23\", \"fld24\", \"fld25\", \"fld26\", \"fld27\", \"fld28\", \"fld29\", \"fld30\", \"fld31\", \"fld32\", \"fld33\", \"fld34\", \"fld35\", \"fld36\", \"fld37\", \"fld38\", \"fld39\", \"fld40\", \"fld41\", \"fld42\", \"fld43\", \"fld44\", \"fld45\", \"fld46\", \"fld47\", \"fld48\", \"fld49\", \"fld50\"])\n",
    "\n",
    "for i in range(0,7):\n",
    "    predictions = rf.predict(test_features)\n",
    "    test_features[0][0]=test_features[0][1]\n",
    "    test_features[0][1]=predictions\n",
    "    Current_Date = datetime.datetime.strptime((datetime.datetime.today() + datetime.timedelta(days=i)).strftime ('%m/%d/%Y'),'%m/%d/%Y')df = df.append({'proj_id': 1, 'project_nm': 'order_0222','date':Current_Date,'fld10': 'Validation','fld11':int(predictions)},ignore_index=True)\t\n",
    "print(\"data:\",df)\n",
    "engine = create_engine(\"mysql+mysqldb://root:\"+'passw0rd'+\"@10.100.112.85/connect_test\")\n",
    "df[0:1].to_sql(con=engine, name='hourly_pred_history', if_exists='append' ,index=False)\n",
    "df[1:7].to_sql(con=engine, name='hourly_pred1', if_exists='replace' ,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friday'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime(\"%A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['29814252', '29796181', None]], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[('29814252'),('29796181'),None]])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][2] = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['29814252', '29796181', 'hi']], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
